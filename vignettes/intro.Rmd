---
title: "Welcome to Data Airlines"
author: "Ben Baumer"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Welcome to Data Airlines}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

The `airlines` package provides a user-friendly interface to create and maintain an SQL database of flight information from the [U.S. Bureau of Transportation Statistics Airline On-Time Performance](http://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&Link=0) data. The user of the `airlines` package only needs a valid place to store the data -- no sophisticated SQL administration skills are necessary. 

## Install packages

The `etl` package provides the generic framework for the `airlines` package. To install the `airlines` package, you must install `etl` first. Since `airlines` package currently lives on GitHub and not on CRAN, you have to install it manually. 

```{r, eval=FALSE, message=FALSE}
install.packages("devtools")
devtools::install_github("beanumber/airlines")
```

To begin, load the `airlines` package. Note that this loads `etl`, which in turn loads `dplyr`. 

```{r, message=FALSE}
library(airlines)
```

## Setting up a database

The data accessible through the `airlines` package is **medium data**. The full data set stretches back to 1987, and provides information on more than 160 million flights (as of 2016). Simply downloading this data could take hours and will occupy more than 6 gigabytes of disk space. For most users, the `flights` table is far too big to store in memory. At the same time, these data are not "big", in the sense that no servers or computing clusters are required -- any recent laptop is perfectly capable of handling data of this magnitude. What is needed is a storage and retrieval system that is capable of storing all of the data on disk, but only loading some of it into memory. SQL is a venerable solution for this problem. 

In order to work with the `airlines` data, you need two things:

+ `dir`: a local directory to store files. If you don't specify one, a temporary directory will be created for you.
+ `db`: a connection to an SQL database that inherits from `dplyr::src_sql`. If you don't specify one, a [SQLite](http://www.sqlite.org) database will be created for you in `dir`. Given the size of the data, you might do better with a [MySQL](http://www.mysql.com) or [PostgreSQL](http://www.postgresql.com) database, but these require external configurations that can be intimidating if you are not already familiar with SQL. If you're a newbie, get started with SQLite, but at some point you might want to [consider alternatives](https://www.sqlite.org/whentouse.html). 

To use the default SQLite source, simply instantiate a new `etl` object. 

```{r}
# use default temporary directory and SQLite database
airlines <- etl("airlines")
```

## Populating the database

If the database has not been populated yet, we use the `etl_create` function to initialize it and insert some data. 

```{r, eval=FALSE}
airlines %>%
  etl_create(years = 1987, months = 10)
```

During initialization, four supplementary tables will be created in the database. These contain information about `planes`, `airports`, and `carriers`. The more substantial data about `flights` will be downloaded from the BTS site, unzipped, loaded into R, and then pumped into your database. 

Once the database is set up, you can update the flights table with more data.  

```{r, eval=FALSE}
airlines %>%
  etl_update(years = 1987, months = 11:12) %>%
  etl_update(years = 1988)
```

Given more time, we might loop through many years. **NOTE: this will take a looong time.** On my computer, it took a little more than an hour to download the files, which occupied more than 6 gigabytes on disk, it took about an hour and fifteen minutes to transform the files, which occupied another 15 gigabytes, and it took another two hours to load the data into MySQL (see below) -- those data occupied another 30 gigabytes on disk. 

```{r, eval=FALSE}
airlines %>%
  etl_update(years = 1988:2016)
```

If the process get disturbed, you can fine-tune using the individual [ETL](https://github.com/beanumber/etl/blob/master/README.md) functions (e.g. `etl_extract`, `etl_transform` and `etl_load`). Note that `etl_update` is just a wrapper for these functions.

```{r}
getS3method("etl_update", "default")
```

Furthermore, `etl_create` is just a wrapper for `etl_update`, with the `schema` argument set.

```{r}
getS3method("etl_create", "default")
```

The ZIP files that are downloaded to your hard drive by `etl_extract` and the CSV files that are subsequently created by `etl_transform` can fill up several gigabytes of space. If you want to clear all that data once you have it safely in your SQL database, use `etl_cleanup` -- but use it **with caution**. Once you delete the ZIP files you will have to re-download them again if you run `etl_extract` again. 

```{r, eval=FALSE}
airlines %>%
  etl_cleanup()
```

## Accessing the airlines database

Now that your airlines database has been populated, you can use it just like you would any other `dplyr::src_sql`. 

```{r}
class(airlines)
summary(airlines)
```

It contains the following tables:

```{r, eval=FALSE}
src_tbls(airlines)
```

Here is a basic summary of the data you have stored. 

```{r, eval=FALSE}
airlines %>%
  tbl("flights") %>%
  group_by(year, origin) %>%
  summarise(N = n(), numDests = n_distinct(dest), 
           numCarriers = n_distinct(carrier), 
           numPlanes = n_distinct(tailnum)) %>%
  arrange(desc(N))
```


## Verification

It is important to verify the integrity of the data. This should return about 163 million flights from October 1987 to June 2015. 

```{r, eval=FALSE}
airlines %>%
  tbl(from = "flights") %>%
  summarise(numFlights = n())
```

If you want to check for individual years, use the `group_by` verb. 

```{r, eval=FALSE}
airlines %>%
  tbl(from = "flights") %>%
  group_by(year) %>%
  summarise(numMonths = count(distinct(month)), numFlights = n()) %>%
  print(n = 40)
```

## MySQL installation

SQLite doesn't support some features (like [partitions](https://en.wikipedia.org/wiki/Partition_(database))) that will be useful for these data. You might want to connect to a MySQL or PostgreSQL database instead. Furthermore, since we are going to be downloading a lot of files, it's a good idea to keep them somewhere where they won't get thrown away when you restart R. We'll specify a place to store the raw and intermediate files that we create.

```{r, eval=FALSE}
# must have pre-existing database "airlines"
db <- src_mysql(host = "localhost", user = "r-user", password = "mypass", dbname = "airlines")
airlines <- etl("airlines", db, dir = "~/dumps/airlines")
```

Note that this assumes that the database `airlines` already exists on the local MySQL server. For instructions on how to set this up, please see the server administrator. 


If you want to see the initialization script, locate the file using `get_schema`. 

```{r}
init <- system.file("sql", "init.mysql", package = "airlines")
head(readLines(init), 10)
```


### Partitioning

For MySQL users, the default schema uses [partitioning](https://dev.mysql.com/doc/refman/5.7/en/partitioning.html) to put each year of flights in its own file on disk. The full table is still available to the user, but if you are often querying individual years, you may see substantial performance improvements on a partitioned table. 

In a *nix environment, you can check the size of your partitions easily using the command line. The MySQL data directory may be a different place depending on your operating system and your installation, but on Ubuntu the default location is `/var/lib/mysql/` and on Mac OS X it is `/usr/local/mysql/data/`. To see the size of the partitions, try:

```{bash, eval=FALSE}
sudo ls -lhS /var/lib/mysql/airlines/ | grep .MYD
```

## Recover nycflights13

Hadley Wickham's [`nycflights13`](https://cran.r-project.org/web/packages/nycflights13/index.html) package is a predecessor to this one. In fact, `nycflights13` is based on a subset of the full data available through `airlines`. To restrict this to only flights from the three New York City airports in 2013, we can simply use `filter`:

```{r, eval=FALSE}
nycFlights13 <- airlines %>%
  tbl("flights") %>%
  filter(year == 2013) %>%
  filter(origin %in% c("JFK", "LGA", "EWR"))

tbl_list <- trim(db, flights = nycFlights13)
airports <- collect(tbl_list$airports)
# save(airports, file = "data/airports.rda")
```
